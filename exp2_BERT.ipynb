{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get BERT ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('mit_final.xlsx', index_col=0)\n",
    "df['all'] = df['intro'] + ' ' + df['leadership'] + ' ' + df['challenge'] + ' ' + df['weakness'] + ' ' + df['whyhire']\n",
    "\n",
    "ratings = pd.read_csv('turker_scores_full_interview.csv', index_col=0)\n",
    "ratings = ratings[ratings['Worker'] == 'AGGR']\n",
    "\n",
    "data = pd.concat([df, ratings], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(data, column_question):\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    import string\n",
    "    \n",
    "    sws = ['pretty', 'uhm', 'uhmm', 'hmmm', 'uhmmm', 'um', 'umm', 'ummm', 'ummmm', 'mmmmmm', 'uh', 'uhh', 'uhhh', 'ah', \n",
    "          'ahh', 'ahhh', 'ok', 'interviewee', 'okay', 'yeah', 'inaudible', 'hmm',\n",
    "          'laughs', 'alright', 'well', 'heh', 'oh', 'ohh', 'ohhh', 'hm', 'hmm', 'hmmmm', 'yea', 'yes', 'yeah']\n",
    "#     sws = sw + stopwords.words('english')\n",
    "\n",
    "    import re\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    regex2 = re.compile('interviewee')\n",
    "    \n",
    "    x = data[column_question].values    \n",
    "    x_clean = []\n",
    "    \n",
    "    for line in x:\n",
    "        line = str(line).lower()\n",
    "        line = line.encode(\"ascii\", \"ignore\")\n",
    "        line = line.decode()\n",
    "\n",
    "        line = regex.sub('', line)\n",
    "        line = regex2.sub('', line)\n",
    "        \n",
    "        line_temp = []\n",
    "        for token in line.rstrip().split():\n",
    "            if token not in sws:\n",
    "                line_temp.append(token)\n",
    "        x_clean.append(\" \".join(line_temp))\n",
    "        \n",
    "\n",
    "        \n",
    "    return x_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_i = get_x(data, 'intro')\n",
    "x_l = get_x(data, 'leadership')\n",
    "x_c = get_x(data, 'challenge')\n",
    "x_w = get_x(data, 'weakness')\n",
    "x_h = get_x(data, 'whyhire')\n",
    "x_all = get_x(data, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_overall = data['Overall'].values\n",
    "y_hire = data['RecommendHiring'].values\n",
    "# y_colleague = data['Colleague'].values\n",
    "# y_eng = data['Engaged'].values\n",
    "y_excit = data['Excited'].values\n",
    "y_eye = data['EyeContact'].values\n",
    "y_smiled = data['Smiled'].values\n",
    "y_rate = data['SpeakingRate'].values\n",
    "y_nofiller= data['NoFillers'].values\n",
    "y_friendly = data['Friendly'].values\n",
    "y_paused = data['Paused'].values\n",
    "y_engtone = data['EngagingTone'].values\n",
    "y_str = data['StructuredAnswers'].values\n",
    "y_calm = data['Calm'].values\n",
    "y_notstress = data['NotStressed'].values\n",
    "y_focused = data['Focused'].values\n",
    "y_auth = data['Authentic'].values\n",
    "y_notawk = data['NotAwkward'].values\n",
    "y_total = data['Total'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518\n"
     ]
    }
   ],
   "source": [
    "Xs = [x_i, x_l, x_c, x_w, x_h]\n",
    "Ys = [y_overall, y_hire, y_excit, y_eye, y_smiled, y_rate, y_nofiller, y_friendly, y_paused, \n",
    "      y_engtone, y_str, y_calm, y_notstress, y_focused, y_auth, y_notawk, y_total]\n",
    "\n",
    "max_len = 0\n",
    "for x in Xs:\n",
    "    for sent in x:\n",
    "        input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "        max_len = max(max_len, len(input_ids))\n",
    "        \n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# params = {'alpha':[0.0001, 0.001, 0.01, 1, 10], 'tol':[0.1, 1, 10]}\n",
    "# params2 = {'epsilon':[0.0001, 0.001, 0.01, 1, 10], 'tol':[0.01, 0.1, 1, 10], 'C':[1, 10, 100, 1000]}\n",
    "\n",
    "# model4 = Lasso()\n",
    "# model5 = SVR()\n",
    "\n",
    "# g = GridSearchCV(model4, params, return_train_score=True, cv=5)\n",
    "# g2 = GridSearchCV(model5, params2, return_train_score=True, cv=5)\n",
    "\n",
    "# lasso = Lasso(alpha=0.01, tol=1)\n",
    "# lasso = Lasso(alpha=0.001, tol=10)\n",
    "# reg = SVR(C=1000, epsilon=0.0001, tol=0.001, gamma='scale')\n",
    "\n",
    "# svr = SVR(gamma='scale')\n",
    "# ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models\n",
    "lasso = Lasso(alpha=0.01, tol=1)\n",
    "svr = SVR(C=1, gamma='scale', epsilon=0.001, tol=0.1)\n",
    "# svr = SVR(C=1, gamma='scale', epsilon=0.001, tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bert_4_sum(x):\n",
    "    input_ids = []\n",
    "    for sent in x:\n",
    "        encoded_dict = tokenizer.encode_plus(sent, add_special_tokens=True, max_length=512, padding='max_length',\n",
    "                                            return_tensors='pt', truncation=True)\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    tokens_tensor = input_ids.clone().detach() #alternative for: tokens_tensor = torch.tensor(input_ids)\n",
    "    \n",
    "    outputs = model(tokens_tensor)\n",
    "    \n",
    "    embeddings = torch.stack(outputs[2][-4:]).sum(0)\n",
    "    embeddings = embeddings.detach().numpy()\n",
    "    result = embeddings.mean(axis=(1))\n",
    "\n",
    "    return result\n",
    "\n",
    "def run_bert_4_cat(x):\n",
    "    input_ids = []\n",
    "    for sent in x:\n",
    "        encoded_dict = tokenizer.encode_plus(sent, add_special_tokens=True, max_length=512, padding='max_length',\n",
    "                                            return_tensors='pt', truncation=True)\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    tokens_tensor = input_ids.clone().detach() #alternative for: tokens_tensor = torch.tensor(input_ids)\n",
    "    \n",
    "    outputs = model(tokens_tensor)\n",
    "    \n",
    "    embeddings = torch.cat([outputs[2][i] for i in [-1,-2,-3,-4]], dim=-1)\n",
    "    embeddings = embeddings.detach().numpy()\n",
    "    result = embeddings.mean(axis=(1))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def run_bert_all(x):\n",
    "    input_ids = []\n",
    "    for sent in x:\n",
    "        encoded_dict = tokenizer.encode_plus(sent, add_special_tokens=True, max_length=512, padding='max_length',\n",
    "                                            return_tensors='pt', truncation=True)\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    tokens_tensor = input_ids.clone().detach() #alternative for: tokens_tensor = torch.tensor(input_ids)\n",
    "    \n",
    "    outputs = model(tokens_tensor)\n",
    "    \n",
    "    embeddings = torch.stack(outputs[2][:]).sum(0)\n",
    "    embeddings = embeddings.detach().numpy()\n",
    "    result = embeddings.mean(axis=(1))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def run_bert_2(x):\n",
    "    input_ids = []\n",
    "    for sent in x:\n",
    "        encoded_dict = tokenizer.encode_plus(sent, add_special_tokens=True, max_length=512, padding='max_length',\n",
    "                                            return_tensors='pt', truncation=True)\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    tokens_tensor = input_ids.clone().detach() #alternative for: tokens_tensor = torch.tensor(input_ids)\n",
    "    \n",
    "    outputs = model(tokens_tensor)\n",
    "    \n",
    "    embeddings = outputs[2][-2].clone().detach()\n",
    "    embeddings = embeddings.detach().numpy()\n",
    "    result = embeddings.mean(axis=(1))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run_bert_4_sum on each question(x_i, x_l, x_c, x_w, x_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_4_sum(x_i)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final1 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final1[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_4_sum(x_l)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final2 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final2[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_4_sum(x_c)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final3 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final3[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_4_sum(x_w)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final4 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final4[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_4_sum(x_h)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final5 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final5[k2] = avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run_bert_4_cat on each question(x_i, x_l, x_c, x_w, x_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_4_cat(x_i)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final6 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final6[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_4_cat(x_l)\n",
    "svr = SVR(C=1, gamma='scale', epsilon=0.001, tol=0.1)\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final7 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final7[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_4_cat(x_c)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final8 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final8[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_4_cat(x_w)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final9 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final9[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_4_cat(x_h)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final10 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final10[k2] = avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run_bert_all on each question(x_i, x_l, x_c, x_w, x_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_all(x_i)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final11 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final11[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_all(x_l)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final12 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final12[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_all(x_c)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final13 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final13[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_all(x_w)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final14 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final14[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_all(x_h)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final15 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final15[k2] = avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run_bert_2 on each question(x_i, x_l, x_c, x_w, x_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_2(x_i)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final16 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final16[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_2(x_l)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final17 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final17[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_2(x_c)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final18 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final18[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_2(x_w)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final19 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final19[k2] = avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = run_bert_2(x_h)\n",
    "\n",
    "alles = {}\n",
    "k = 5\n",
    "unit = len(x) // k\n",
    "for i in range(k):\n",
    "    results = {}\n",
    "    for j, y in enumerate(Ys):\n",
    "        y = np.array(y)\n",
    "        x_test = x[i*unit:(i+1)*unit]\n",
    "        y_test = y[i*unit:(i+1)*unit]\n",
    "        x_train = np.concatenate((x[:i*unit], x[(i+1)*unit:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i*unit], y[(i+1)*unit:]), axis=0)\n",
    "        svr.fit(x_train, y_train)\n",
    "        preds = svr.predict(x_test)\n",
    "        result = np.corrcoef(y_test, preds)\n",
    "        results[str(j+1)] = result\n",
    "    alles[i] = results\n",
    "\n",
    "final20 = {}\n",
    "for k, v in alles.items():\n",
    "    for k2, v2 in v.items():\n",
    "        avg = np.mean(v2)\n",
    "        final20[k2] = avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compile results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>concat</th>\n",
       "      <th>all</th>\n",
       "      <th>sec-to-last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608362</td>\n",
       "      <td>0.614127</td>\n",
       "      <td>0.610146</td>\n",
       "      <td>0.606648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.543967</td>\n",
       "      <td>0.543501</td>\n",
       "      <td>0.536379</td>\n",
       "      <td>0.531589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.557312</td>\n",
       "      <td>0.585144</td>\n",
       "      <td>0.547163</td>\n",
       "      <td>0.585276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.475803</td>\n",
       "      <td>0.536917</td>\n",
       "      <td>0.467098</td>\n",
       "      <td>0.531133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.589054</td>\n",
       "      <td>0.525187</td>\n",
       "      <td>0.560763</td>\n",
       "      <td>0.461329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.793493</td>\n",
       "      <td>0.813065</td>\n",
       "      <td>0.774446</td>\n",
       "      <td>0.814646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.655339</td>\n",
       "      <td>0.653210</td>\n",
       "      <td>0.692333</td>\n",
       "      <td>0.636479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.575442</td>\n",
       "      <td>0.568305</td>\n",
       "      <td>0.586596</td>\n",
       "      <td>0.558983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.685767</td>\n",
       "      <td>0.670436</td>\n",
       "      <td>0.704231</td>\n",
       "      <td>0.675066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.569051</td>\n",
       "      <td>0.547957</td>\n",
       "      <td>0.603551</td>\n",
       "      <td>0.548322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sum    concat       all  sec-to-last\n",
       "1   0.608362  0.614127  0.610146     0.606648\n",
       "2   0.543967  0.543501  0.536379     0.531589\n",
       "3   0.557312  0.585144  0.547163     0.585276\n",
       "4   0.475803  0.536917  0.467098     0.531133\n",
       "5   0.589054  0.525187  0.560763     0.461329\n",
       "..       ...       ...       ...          ...\n",
       "13  0.793493  0.813065  0.774446     0.814646\n",
       "14  0.655339  0.653210  0.692333     0.636479\n",
       "15  0.575442  0.568305  0.586596     0.558983\n",
       "16  0.685767  0.670436  0.704231     0.675066\n",
       "17  0.569051  0.547957  0.603551     0.548322\n",
       "\n",
       "[85 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = pd.DataFrame([final1, final6, final11, final16]).T\n",
    "q1 = q1.rename(columns={0:'sum', 1:'concat', 2:'all', 3:'sec-to-last'})\n",
    "q2 = pd.DataFrame([final2, final7, final12, final17]).T\n",
    "q2 = q2.rename(columns={0:'sum', 1:'concat', 2:'all', 3:'sec-to-last'})\n",
    "q3 = pd.DataFrame([final3, final8, final13, final18]).T\n",
    "q3 = q3.rename(columns={0:'sum', 1:'concat', 2:'all', 3:'sec-to-last'})\n",
    "q4 = pd.DataFrame([final4, final9, final14, final19]).T\n",
    "q4 = q4.rename(columns={0:'sum', 1:'concat', 2:'all', 3:'sec-to-last'})\n",
    "q5 = pd.DataFrame([final5, final10, final15, final20]).T\n",
    "q5 = q5.rename(columns={0:'sum', 1:'concat', 2:'all', 3:'sec-to-last'})\n",
    "allresult = pd.concat([q1, q2, q3, q4, q5], axis=0)\n",
    "allresult\n",
    "# allresult.to_csv('bert_svr.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
